{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Gavin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gavin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import pickle\n",
    "import sqlalchemy\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "nltk.downloader.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 10-K Data from the Database\n",
    "db_name = \"SEC_Filings.db\"\n",
    "table_name = \"10K_Data\"\n",
    "\n",
    "engine = sqlalchemy.create_engine('sqlite:///' + db_name, execution_options={\"sqlite_raw_colnames\": True})\n",
    "df = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "# Clean DataFrame\n",
    "agri = ['0100', '0200', '0900']\n",
    "fin = ['6172', '6199', '6200', '6211', '6221', '6282']\n",
    "air = ['4513', '4522', '4581']\n",
    "bank = ['6022', '6029', '6035', '6036', '6099']\n",
    "\n",
    "df['Industry'] = ''\n",
    "df.loc[df['SIC'].isin(agri), 'Industry'] = \"Agriculture\"\n",
    "df.loc[df['SIC'].isin(fin), 'Industry'] = \"Financial Services\"\n",
    "df.loc[df['SIC'].isin(air), 'Industry'] = \"Aviation\"\n",
    "df.loc[df['SIC'].isin(bank), 'Industry'] = \"Banking\"\n",
    "\n",
    "df = df.drop(['Filing_Link', 'Accession_No', 'SIC', 'Company'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "# Set 'Aspect' Words\n",
    "word_search_list_2 = [{'artificial intelligence': ['artificial intelligence', 'artificial-intelligence', ' ai.', ' ai,', ' ai ']},\n",
    "                      {'deep learning': ['deep learning', 'deep-learning']}, \n",
    "                      {'computer vision': ['computer vision', 'computer-vision']}, \n",
    "                      'bots', \n",
    "                      'automation', \n",
    "                      {'machine learning': ['machine learning', 'machine-learning']},\n",
    "                      'algorithm']\n",
    "# aspects = [list(x.values())[0] if isinstance (x, dict) else x for x in word_search_list_2]\n",
    "\n",
    "# Convert 10-K Text to String\n",
    "# review_text = df['Filing_Document_Text'][0]\n",
    "\n",
    "# State Sentiment Analyzer - Rule-based Approach\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create DataFrame to Store Output\n",
    "df_sentiments = pd.DataFrame(columns=['Industry', 'Year', 'Aspect', 'Count', 'Sentiment'])\n",
    "\n",
    "df['Filing_Date'] = pd.to_datetime(df['Filing_Date'], format='%Y-%m-%d')\n",
    "# Perform Sentiment Analysis\n",
    "\n",
    "out_list = []\n",
    "for i, review_text in enumerate(df['Filing_Document_Text']):\n",
    "\n",
    "    # Create Dictionary to Store Sentiment Scores\n",
    "    aspect_sentiments = {}\n",
    "    for aspect_item in word_search_list_2:\n",
    "        if isinstance(aspect_item, dict):\n",
    "            aspect = list(aspect_item.keys())[0]\n",
    "            aspect_sentiments[aspect] = {'count': 0, 'sentiment': 0}\n",
    "        else:\n",
    "            aspect_sentiments[aspect_item] = {'count': 0, 'sentiment': 0}\n",
    "\n",
    "    year = df.loc[i,'Filing_Date'].year\n",
    "    industry = df.loc[i,'Industry']\n",
    "    \n",
    "    sentences = sent_tokenize(review_text)\n",
    "    for sentence in sentences:\n",
    "        for aspect_item in word_search_list_2:\n",
    "            if isinstance (aspect_item, dict):\n",
    "                aspect = list(aspect_item.keys())[0]\n",
    "                keywords = list(aspect_item.values())[0]\n",
    "                for keyword in keywords:\n",
    "                    if keyword in sentence.lower():\n",
    "                        sent_score = sia.polarity_scores(sentence)\n",
    "                        aspect_sentiments[aspect]['count'] += 1\n",
    "                        aspect_sentiments[aspect]['sentiment'] += sent_score['compound']\n",
    "            else:\n",
    "                aspect = aspect_item\n",
    "                if aspect in sentence.lower():\n",
    "                    sent_score = sia.polarity_scores(sentence)\n",
    "                    aspect_sentiments[aspect]['count'] += 1\n",
    "                    aspect_sentiments[aspect]['sentiment'] += sent_score['compound']\n",
    "    \n",
    "    for aspect in aspect_sentiments:\n",
    "        count = aspect_sentiments[aspect]['count']\n",
    "        sent = aspect_sentiments[aspect]['sentiment']\n",
    "        out_data = {'Industry': industry, 'Year': year, 'Aspect': aspect, 'Count': count, 'Sentiment': sent}\n",
    "        out_list.append(out_data)\n",
    "\n",
    "df_sentiments = pd.DataFrame.from_dict(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df_agg = df_sentiments[['Industry', 'Aspect', 'Year', 'Count', 'Sentiment']].groupby(['Industry', 'Aspect', 'Year']).sum()\n",
    "df_agg['Aggregated Sentiment'] = 0\n",
    "df_agg.loc[df_agg['Count']!=0, 'Aggregated Sentiment'] = df_agg['Sentiment']/df_agg['Count']\n",
    "df_agg.reset_index(drop=False, inplace=True)\n",
    "df_agg.drop('Sentiment', axis=1, inplace=True)\n",
    "\n",
    "df_agg = df_agg.loc[~df_agg['Aspect'].isin(['computer vision', 'deep learning'])].reset_index(drop=True)\n",
    "df_agg=df_agg.loc[df_agg['Count'] > 5].reset_index(drop=True)\n",
    "\n",
    "industry_counts = df_sentiments[['Industry', 'Year']].groupby('Industry').count()/len(word_search_list_2)\n",
    "for industry in df_agg['Industry'].unique():\n",
    "    df_agg.loc[df_agg['Industry']==industry, 'Average Mentions'] = df_agg['Count']/industry_counts.loc[industry].values\n",
    "\n",
    "df_agg.to_sql(\"Aggregated_Sentiment_Scores\", engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
